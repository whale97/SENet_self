# 학사 졸업논문  
# SENet에 Multihead_self_attention을 추가한 구조 모델링  

## INDEX  
1. 서론   
  1) 연구의 필요성   
Vision Transformer는 자연어 처리에서 많이 사용되었던 Transformer를 이미지 처리에 도입한 것이다. ViT의 핵심 아이디어인 multi-head attention의 특성을 탐구해 보고자, ResNet에 Self-Attention Block을 추가해 Self-attention의 특징과 Convolutional Network에 이를 적용했을 때의 성능차이에 대한 연구를 해 보고자 한다. ILSVRC 2017 우승 모델인 SENet의 핵심 아이디어 squeeze and excitation이 Image에 대하여 attention을 적용한 기법이다. ResNet에 SE-Block만 추가한 구조가 되는데, 이 SE-Block을 변형시켜 attention에 self-attention을 더한 모델을 연구해 보고자 한다.   
  2) 관련 연구   
  
  3) 연구계획   
2. 본문   
  1) 방법   
  2) Experiment   
  3) 분석 & 비교   
3. 결론   
참고문헌  

